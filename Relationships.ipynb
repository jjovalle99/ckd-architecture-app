{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llama_parse import LlamaParse\n",
    "from nest_asyncio import apply as nest_asyncio_apply\n",
    "\n",
    "_ = nest_asyncio_apply(), load_dotenv()\n",
    "DATA = Path(\"data/whitepapers/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=os.getenv(\"LLAMA_PARSE_API_KEY\"),\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    "    num_workers=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 31814d4b-9509-400e-9ab7-ecb69b82880d\n",
      "Started parsing the file under job_id 2e4574e1-bbbd-4b42-8331-bbe75ededbca\n",
      "Started parsing the file under job_id 2a700e38-470c-4872-ad72-ce18ef39d127\n",
      "Started parsing the file under job_id 7e85df9a-4981-4737-bc23-8550f41118c1\n",
      "Started parsing the file under job_id a641004d-53ba-4634-9d27-0b6c06c5695a\n",
      "Started parsing the file under job_id 74019ba2-3511-4b05-a5cd-e56a23d1e9a3\n",
      "Started parsing the file under job_id 1c70181f-1b18-4150-ba24-f709b163265c\n",
      "..."
     ]
    }
   ],
   "source": [
    "file_path = [str(DATA / \"2024\" / file) for file in os.listdir(DATA / \"2024\")]\n",
    "documents = await parser.aload_data(file_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extractor Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248997\n"
     ]
    }
   ],
   "source": [
    "print(len(documents[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/services_data_sc.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "services = \", \".join([service[\"service_name\"] for service in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGRelationship(BaseModel):\n",
    "    f\"\"\"Relationship between two of the following AWS services: {services}\"\"\"\n",
    "    service_1: Optional[str] = Field(..., description=\"Service 1, that has a connection with Service 2\")\n",
    "    service_2: Optional[str] = Field(..., description=\"Service 2, that receives the connection from Service 1\")\n",
    "    evidence: Optional[str] = Field(..., description=\"Verbatim sentence of the text where the relationship was found\")\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted relationships between AWS Services\"\"\"\n",
    "    relationships: List[KGRelationship] = Field(..., description=\"List of relationships between AWS Services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert at identifying relationships between AWS Services. \"\n",
    "            f\"Only extract directed connections between services. What relationships mean is that the two services are used often in an architecture. Extract nothing if no important information can be found in the text. You must only extract relationships between the following services: {services}\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-0125-preview\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = prompt | llm.with_structured_output(\n",
    "    schema=Data,\n",
    "    method=\"function_calling\",\n",
    "    include_raw=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(documents[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_few = texts[3:6]\n",
    "\n",
    "extractions = await extractor.abatch(\n",
    "    [{\"text\": text} for text in first_few],\n",
    "    {\"max_concurrency\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KGRelationship(service_1='AWS Control Tower', service_2='AWS Organizations', evidence='Define your AWS accounts strategy and leverage AWS Control Tower and AWS Organizations to build landing zones to provide ongoing account management, governance, and implementation of AWS best practices.'),\n",
       " KGRelationship(service_1='AWS Well-Architected Framework', service_2='AWS Migration Hub', evidence='Your migration planning is the key to a successful migration to AWS, and needs to cover many aspects. These include ensuring you have the right skills at the points when they are needed and the capacity required to meet your timeline, scope, and budget.')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationships = []\n",
    "\n",
    "for extraction in extractions:\n",
    "    relationships.extend(extraction.relationships)\n",
    "\n",
    "relationships[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KGRelationship(service_1='AWS Well-Architected Framework', service_2='Amazon EC2', evidence='Throughout the migration, a wide range of decisions need to be made, such as the target Amazon Elastic Compute Cloud (Amazon EC2) instance type or what type of Amazon Elastic Block Store (Amazon EBS) to use.'),\n",
       " KGRelationship(service_1='AWS Well-Architected Framework', service_2='Amazon EBS', evidence='Throughout the migration, a wide range of decisions need to be made, such as the target Amazon Elastic Compute Cloud (Amazon EC2) instance type or what type of Amazon Elastic Block Store (Amazon EBS) to use.'),\n",
       " KGRelationship(service_1='AWS Professional Services', service_2='AWS Managed Services', evidence='Alternatively, you may decide to leverage AWS Managed Services to extend your team with operational capabilities, including monitoring, incident management, AWS Incident Detection and Response, security, patch, backup, and cost optimization for migrated workloads.'),\n",
       " KGRelationship(service_1='AWS Managed Services', service_2='AWS Incident Detection and Response', evidence='Alternatively, you may decide to leverage AWS Managed Services to extend your team with operational capabilities, including monitoring, incident management, AWS Incident Detection and Response, security, patch, backup, and cost optimization for migrated workloads.'),\n",
       " KGRelationship(service_1='AWS Application Migration Service', service_2='Amazon EC2', evidence='When using a rehost migration pattern, your source workloads are cloned into AWS, and when they launch on the Amazon EC2 platform, they may attempt to speak to the services and applications')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationships = []\n",
    "\n",
    "for extraction in extractions:\n",
    "    relationships.extend(extraction.relationships)\n",
    "\n",
    "relationships[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
